---
title: "PL + X"
excerpt_separator: "<!--more-->"
categories:
  - Blog
---

Three ways to think like Programming Languages (PL) researcher.

<!-- # It's a Program, Silly!

**Increase the expressiveness of your API by letting users write arbitrary programs.**

APIs frequently start out by identifying the *primitives* people need for their domain. For example,
convolutions and fully connected layers are two common primitives in machine learning. However, just
as important are how those primitives are *composed* with each other.

APIs often start off with weak
forms of composition. For example, you might start building an ML framework that allows someone to
just write straightline networks. But soon you realize you need loops, conditionals, and dynamically
sized tensors. Concepts like `tf.while_loop` begin to emerge.

Another example of this is templates in web frameworks. Consider the following from Vue:

```tsx
<li v-for="item in items">
  { { item.message } }
</li>
```

vs. the equivalent in React:

```tsx
{items.map((item) => <li>{item.message}</li>)}
```

We can argue about the *readability* of these two. The point I want to make is about the relative
*expressiveness.*

On the other hand, you might be able to argue that a small number of control flow operators suffices
here. You can just push the rest of it into logic and leave simple loops and conditionals for the
templates.

This is one way in which (Greenspun's
tenth rule)[https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule] manifests. Developers often start with
a simple collection of compositions only to later realize they need a full programming language
with control flow, functions, and even macros to achieve the expressiveness people want. (See also: https://subconscious.substack.com/p/a-kardashev-scale-for-interfaces)

Here are some specific examples where there exist static directed acyclic graph (DAG) APIs and analogous,
more powerful DSLs.

- PyTorch: In contrast to approaches like TensorFlow which are (well, used to be) based around
  static DAGs, PyTorch allows people to write arbitrary Python code.
- Puddle: ... (See above)
- Incremental Computation: In contrast to some build systems, which use static DAGs, languages like
  SkipLang let users write arbitrary code.

DAGs seem to work best at the level of composing together arbitrary code, say in file dependency
structures or computational notebooks. Unlike the systems above, these systems tend to be pretty
stable, because you always have a general purpose language at hand by pushing the code from the
upper-level DAG into a specific node, at the expense of losing the UI affordances like a file system
viewer or graph editor. -->

# Now What You Have Here Is a Compiler

**Design separate human- and machine-level abstractions.**

There are a few key ideas here:
- you can separate the languages, they don't have to be the same! they probably shouldn't be!
- separating the languages also allows you to search over many different low-level, equivalent
  programs to find ones that fit your high-level specification
- the languages don't need to run in traditional ways!

- Carpentry Compiler
- 3D Knitting Compiler
- Software-Defined Networks??? (NetKAT????) Kleene* + -> ONF

There are a few benefits I see of identifying that what you're building is a compiler. The first one
is the ability to re-architect your system as a [nanopass
compiler](https://blog.sigplan.org/2019/07/09/my-first-fifteen-compilers/). That is, you should
be able to split your compiler into a pipeline of very small code transformations where each step in
the pipeline ingests and produces a self-contained program. This structure is useful because it
avoids the problem of mixing elaboration/default/inference code with actual lowering. Mixing those
hurts debugging and reasoning, because you don't have an explicitly elaborated form of the
high-level code.
- filling in type information
- desugaring for loops to while loops
- filling in default values

Another is access to the vast literature on compiler optimization techniques, type checking, etc.

Another is that it gives you freedom to design several very-different levels. Your user-centered API
and your machine-facing API don't have to be the same.

(See also: https://rachitnigam.com/post/you-have-built-a-compiler/)

# Going In Reverse: Decompilation and Synthesis

**Treat your input data as the output of some unknown process.**

Program/data is the output of some unknown process. We want to recover the input.

- like compilation, this typically involves some sort of search with some objective function
- but the input is typically generated some other "compiler," e.g. a human

- FlashFill
- Szalinski
- K-12 Programs

This area is slowly getting its lunch eaten by ML methods, though neurosymbolic synthesis is
becoming increasingly interesting.

The key here is again to think about these problems as language design problems. Can you come up
with useful representations for machines?

## Software-Defined Networks

everything is a program?

## Probabilistic Programming

everything is a program

## FlashFill

??

## Incremental Computation

everything is a program

## Authenticated Data Structures

????


## Puddle

()[https://misl.cs.washington.edu/projects/fluidics.html]
()[https://www.mwillsey.com/assets/2019-asplos-puddle.pdf]

<video width="50%" controls="" loop="">
  <source src="https://misl.cs.washington.edu/img/droplet-tracking.mp4" type="video/mp4">
</video>

Puddle is an API for microfluidic devices. In contrast to prior approaches that use DAGs (and thus
only allow for straightline code), Puddle lets users write arbitrary Python programs, allowing for
functions, unbounded data structures (e.g. lists), and data-dependent control flow (e.g. an if
statement that depends on input data).

This is similar to the approach that PyTorch takes.

Everything is a program

Dynamism and error correction.

low-level abstractions of the device

resource management

existing approaches encode DAG -> straight-line code

allows for functions, unbounded data structures like lists, data-dependent control flow

## Carpentry Compiler

https://grail.cs.washington.edu/projects/carpentrycompiler/

Everything is a compiler


Decouple design from fabrication process.
A design is a sequence of geometric construction operations.
A fabrication is a sequence of physical instructions. (These instructions are not necessarily
executed by a machine, but may be executed by a human!)

Compiler searches over space of possible fabrication plans to find different tradeoffs between
material cost and fabrication time.

## 3D Knitting Compiler

https://la.disneyresearch.com/publication/machine-knitting-compiler/

Everything is a compiler


High-level shape primitives -> low-level instructions for industrial knitting machines.
High-level primitives: tubes and sheets. needle bed position and construction time
Low-level primitives: knit, tuck, split, transfer

## Programs for K-12 Algebra

e.g.
https://dada.cs.washington.edu/research/tr/2017/10/UW-CSE-17-10-02.pdf

Everything is a program?


## Compilers for Machine Learning

Relay

Everything is a program.

## Szalinski

https://courses.cs.washington.edu/courses/cse599j1/22sp/papers/szalinski.pdf

Everything is a program/compiler.

Convert flat CAD to parameterized CAD.


## Once Something Is a Program You Can...

- compile it
- decompile it
- synthesize it
- analyze it
- optimize it




# PL + X

http://www.pl-enthusiast.net/2015/05/27/what-is-pl-research-and-how-is-it-useful/
